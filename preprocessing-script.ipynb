{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "305dd5a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-05T12:18:27.284812Z",
     "iopub.status.busy": "2023-02-05T12:18:27.284282Z",
     "iopub.status.idle": "2023-02-05T12:18:49.224808Z",
     "shell.execute_reply": "2023-02-05T12:18:49.223538Z"
    },
    "papermill": {
     "duration": 21.949325,
     "end_time": "2023-02-05T12:18:49.227782",
     "exception": false,
     "start_time": "2023-02-05T12:18:27.278457",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0mCollecting nbdev\r\n",
      "  Downloading nbdev-2.3.11-py3-none-any.whl (64 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.5/64.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting watchdog\r\n",
      "  Downloading watchdog-2.2.1-py3-none-manylinux2014_x86_64.whl (78 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.0/79.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting execnb>=0.1.4\r\n",
      "  Downloading execnb-0.1.4-py3-none-any.whl (13 kB)\r\n",
      "Collecting asttokens\r\n",
      "  Downloading asttokens-2.2.1-py2.py3-none-any.whl (26 kB)\r\n",
      "Collecting ghapi>=1.0.3\r\n",
      "  Downloading ghapi-1.0.3-py3-none-any.whl (58 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: PyYAML in /opt/conda/lib/python3.7/site-packages (from nbdev) (6.0)\r\n",
      "Requirement already satisfied: astunparse in /opt/conda/lib/python3.7/site-packages (from nbdev) (1.6.3)\r\n",
      "Requirement already satisfied: fastcore>=1.5.27 in /opt/conda/lib/python3.7/site-packages (from nbdev) (1.5.27)\r\n",
      "Requirement already satisfied: ipython in /opt/conda/lib/python3.7/site-packages (from execnb>=0.1.4->nbdev) (7.33.0)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from fastcore>=1.5.27->nbdev) (22.0)\r\n",
      "Requirement already satisfied: pip in /opt/conda/lib/python3.7/site-packages (from fastcore>=1.5.27->nbdev) (22.1.2)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from asttokens->nbdev) (1.15.0)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.7/site-packages (from astunparse->nbdev) (0.37.1)\r\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from ipython->execnb>=0.1.4->nbdev) (5.1.1)\r\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.7/site-packages (from ipython->execnb>=0.1.4->nbdev) (0.2.0)\r\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.7/site-packages (from ipython->execnb>=0.1.4->nbdev) (4.8.0)\r\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from ipython->execnb>=0.1.4->nbdev) (3.0.30)\r\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.7/site-packages (from ipython->execnb>=0.1.4->nbdev) (0.7.5)\r\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.7/site-packages (from ipython->execnb>=0.1.4->nbdev) (2.12.0)\r\n",
      "Requirement already satisfied: traitlets>=4.2 in /opt/conda/lib/python3.7/site-packages (from ipython->execnb>=0.1.4->nbdev) (5.3.0)\r\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.7/site-packages (from ipython->execnb>=0.1.4->nbdev) (0.1.3)\r\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.7/site-packages (from ipython->execnb>=0.1.4->nbdev) (0.18.1)\r\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.7/site-packages (from ipython->execnb>=0.1.4->nbdev) (59.8.0)\r\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.7/site-packages (from jedi>=0.16->ipython->execnb>=0.1.4->nbdev) (0.8.3)\r\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.7/site-packages (from pexpect>4.3->ipython->execnb>=0.1.4->nbdev) (0.7.0)\r\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->execnb>=0.1.4->nbdev) (0.2.5)\r\n",
      "Installing collected packages: watchdog, asttokens, ghapi, execnb, nbdev\r\n",
      "Successfully installed asttokens-2.2.1 execnb-0.1.4 ghapi-1.0.3 nbdev-2.3.11 watchdog-2.2.1\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -Uq dicomsdl\n",
    "\n",
    "# nbdev requires jupyter, but we're already in a notebook environment, so we can install without dependencies\n",
    "!pip install -U nbdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f2c47ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-05T12:18:49.236976Z",
     "iopub.status.busy": "2023-02-05T12:18:49.236622Z",
     "iopub.status.idle": "2023-02-05T12:18:49.241568Z",
     "shell.execute_reply": "2023-02-05T12:18:49.240462Z"
    },
    "papermill": {
     "duration": 0.011775,
     "end_time": "2023-02-05T12:18:49.243552",
     "exception": false,
     "start_time": "2023-02-05T12:18:49.231777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#|default_exp preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d665e26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-05T12:18:49.252637Z",
     "iopub.status.busy": "2023-02-05T12:18:49.251189Z",
     "iopub.status.idle": "2023-02-05T12:18:53.006480Z",
     "shell.execute_reply": "2023-02-05T12:18:53.005455Z"
    },
    "papermill": {
     "duration": 3.76232,
     "end_time": "2023-02-05T12:18:53.009268",
     "exception": false,
     "start_time": "2023-02-05T12:18:49.246948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#|export\n",
    "from fastai.basics import *\n",
    "from fastai.medical.imaging import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import dicomsdl as dicom\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from joblib import Parallel, delayed\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "183af2e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-05T12:18:53.017893Z",
     "iopub.status.busy": "2023-02-05T12:18:53.017457Z",
     "iopub.status.idle": "2023-02-05T12:18:53.039812Z",
     "shell.execute_reply": "2023-02-05T12:18:53.038811Z"
    },
    "papermill": {
     "duration": 0.029075,
     "end_time": "2023-02-05T12:18:53.041781",
     "exception": false,
     "start_time": "2023-02-05T12:18:53.012706",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "# Base class for preprocessing mammography images\n",
    "class MammoPreprocessorBase():\n",
    "    \n",
    "    def __init__(self, img_path: str, \n",
    "                 image_size: tuple=(4096,2048), dir_name: str=\"Mammography_Dataset\"):\n",
    "        \"\"\"\n",
    "        Initializes the object with the path to the images and desired image size. \n",
    "        Creates a directory to save preprocessed images if it doesn't exist.\n",
    "        \"\"\"\n",
    "        self.img_path = img_path\n",
    "        self.image_size = image_size\n",
    "        if dir_name:\n",
    "            os.makedirs(f\"{dir_name}\", exist_ok=True)\n",
    "            self.save_path = os.path.join(os.getcwd(), dir_name)\n",
    "        self.images = glob.glob(f\"{img_path}/**/*.dcm\", recursive=True)\n",
    "    \n",
    "    def preprocess_all(self, fformat: str, hist_eq=None, n_jobs: int=-1, save=True):\n",
    "        \"\"\"\n",
    "        Preprocesses all images in parallel. \n",
    "        Applies histogram equalization if hist_eq, saves images if save=True.\n",
    "        \"\"\"\n",
    "        Parallel(n_jobs=n_jobs) \\\n",
    "            (delayed(self.preprocess_image) \\\n",
    "            (path, fformat, hist_eq, save) for path in tqdm(self.images, total=len(self.images)))\n",
    "        print(\"Parallel preprocessing done!\")\n",
    "    \n",
    "    \n",
    "    def _hist_eq(self, img, hist_eq=\"hist_eq\"):\n",
    "        # Histogram equalization only works on 8-bit images\n",
    "        img = self._convert_to_8bit(img)\n",
    "        \n",
    "        if hist_eq == \"clahe\":\n",
    "            clahe = cv2.createCLAHE()\n",
    "            img = clahe.apply(img)\n",
    "        \n",
    "        if hist_eq == \"hist_eq\":\n",
    "            img = cv2.equalizeHist(img)\n",
    "        \n",
    "        return img\n",
    "    \n",
    "    def _convert_to_8bit(self,img):\n",
    "        return (img / img.max()*255).astype(np.uint8)\n",
    "    \n",
    "    def _padresize_to_width(self, img, size, mask=None):\n",
    "        \n",
    "        h, w  = img.shape\n",
    "        \n",
    "        # If the width of the image is less than the desired width\n",
    "        if w < size[1]:\n",
    "            # Add padding to the right side of the image to reach the desired width\n",
    "            img = cv2.copyMakeBorder(img, 0, 0, 0, size[1] - w, cv2.BORDER_CONSTANT, value=(0, 0, 0))\n",
    "            if mask is not None:\n",
    "                mask = cv2.copyMakeBorder(mask, 0, 0, 0, size[1] - w, cv2.BORDER_CONSTANT, value=(0, 0, 0))\n",
    "        \n",
    "        # If the width of the image is greater than the desired width\n",
    "        if w > size[1]:\n",
    "            # Resize the image to the desired width\n",
    "            img = cv2.resize(img, (size[1], size[0]))\n",
    "            # Resize the mask if provided with interpolation set to nearest to keep pixel values\n",
    "            if mask is not None:\n",
    "                mask = cv2.resize(mask, (size[1], size[0]), interpolation = cv2.INTER_NEAREST)\n",
    "            \n",
    "        return (img, mask) if mask is not None else img\n",
    "    \n",
    "    # Resize image but keep aspect ratio\n",
    "    def _resize_to_height(self, img, size, mask=None):\n",
    "        \n",
    "        h,w = img.shape\n",
    "        # Calculate aspect ratio\n",
    "        r = h/w\n",
    "        # Resize to desired height and calculate width to keep aspect ratio\n",
    "        new_size = (int(size[0]/r), size[0])\n",
    "        \n",
    "        # cv2.resize takes image size in form (width, height)\n",
    "        img = cv2.resize(img, new_size)\n",
    "        if mask is not None:\n",
    "            # Use nearest interpolation to keep mask pixel values\n",
    "            mask = cv2.resize(mask, new_size, interpolation = cv2.INTER_NEAREST)\n",
    "        \n",
    "        return (img, mask) if mask is not None else img\n",
    "    \n",
    "    def _crop_roi(self, img, mask=None):\n",
    "        \n",
    "        # Binarize image to remove background noise\n",
    "        bin_img = self._binarize(img)\n",
    "        # Find the largest contour\n",
    "        contour = self._find_contours(bin_img)\n",
    "        \n",
    "        # Create a bounding box from the contour\n",
    "        x1, x2 = np.min(contour[:, :, 0]), np.max(contour[:, :, 0])\n",
    "        y1, y2 = np.min(contour[:, :, 1]), np.max(contour[:, :, 1])\n",
    "        \n",
    "        # Use bounding box coordinates to crop the image and mask if provided\n",
    "        return (img[y1:y2, x1:x2], mask[y1:y2, x1:x2]) if mask is not None else img[y1:y2, x1:x2] \n",
    "        \n",
    "    def _remove_background(self, img):\n",
    "        \n",
    "        # Binarize image to remove noise and find the largest contour\n",
    "        bin_img = self._binarize(img)\n",
    "        contour = self._find_contours(bin_img)\n",
    "        \n",
    "        # Create a mask from the contour\n",
    "        mask = np.zeros(bin_img.shape, np.uint8)\n",
    "        cv2.drawContours(mask, [contour], -1, 255, cv2.FILLED)\n",
    "        \n",
    "        # Not working most of the time\n",
    "        if remove_wlines:\n",
    "            white_lines_fix = (mask[:,-1]!=255).astype(np.uint8)[:,None]\n",
    "            mask = (mask * white_lines_fix) / mask.max()\n",
    "        \n",
    "        # Multiply the image with the black and white \n",
    "        return img * mask\n",
    "    \n",
    "    def _find_contours(self, bin_img):\n",
    "    \n",
    "        contours, _ = cv2.findContours(bin_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "        # Select the largest contour\n",
    "        contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "        return contour\n",
    "    \n",
    "    def _binarize(self, img):\n",
    "        \n",
    "        # Binarize the image with a 5% threshold\n",
    "        binarized = (img > (img.max()*0.05)).astype(\"uint8\")\n",
    "        \n",
    "        return binarized\n",
    "\n",
    "    def _correct_side(self, img, mask=None):\n",
    "        \n",
    "        # Split image symetrically\n",
    "        col_sums_split = np.array_split(np.sum(img, axis=0), 2)\n",
    "        # Sum the pixel values on each side\n",
    "        left_col_sum = np.sum(col_sums_split[0])\n",
    "        right_col_sum = np.sum(col_sums_split[1])\n",
    "\n",
    "        # Determine where the breast is by comparing total pixel values\n",
    "        if left_col_sum > right_col_sum: \n",
    "            return (img, mask) if mask is not None else img\n",
    "        # Flip if breast on the right\n",
    "        else: \n",
    "            return (np.fliplr(img), np.fliplr(mask)) if mask is not None else np.fliplr(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66e48642",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-05T12:18:53.050048Z",
     "iopub.status.busy": "2023-02-05T12:18:53.049380Z",
     "iopub.status.idle": "2023-02-05T12:18:53.071604Z",
     "shell.execute_reply": "2023-02-05T12:18:53.070761Z"
    },
    "papermill": {
     "duration": 0.028644,
     "end_time": "2023-02-05T12:18:53.073575",
     "exception": false,
     "start_time": "2023-02-05T12:18:53.044931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "# Class for preprocessing mammography images from CBIS-DDSM\n",
    "# Inherits most methods from base class\n",
    "class MammoPreprocessorCBISDDSM(MammoPreprocessorBase):\n",
    "    \n",
    "    def __init__(self, img_path: str, masks: str=None, \n",
    "               mammo_imgs_csv: str=None, masks_csv: str=None, case_desc_csv: str=None,\n",
    "              image_size: tuple=(4096,2048), dir_name: str=\"CBIS_DDSM\"):\n",
    "    \n",
    "        super().__init__(img_path, image_size, dir_name)\n",
    "        # Cleaning and merging the datasets that came with the images\n",
    "        self.df = self._merge_dfs(mammo_imgs_csv, masks_csv, case_desc_csv)\n",
    "        \n",
    "    def preprocess_image(self, path:str, fformat: str=\"png\", hist_eq=None, save: bool=True):\n",
    "        \n",
    "        # Use dicomsdl to open dcm files (faster than pydicom)\n",
    "        img = dicom.open(path).pixelData()\n",
    "        # Each abnormality has a seperate mask so combine then into one for each image\n",
    "        labels = self._combine_masks(path)\n",
    "        \n",
    "        img, labels = super()._correct_side(img, labels)\n",
    "        img, labels = self._remove_wlines(img, labels)\n",
    "        img = super()._remove_background(img)\n",
    "        img, labels = super()._crop_roi(img, labels)\n",
    "        img, labels = super()._resize_to_height(img, self.image_size, labels)\n",
    "        img, labels = super()._padresize_to_width(img, self.image_size, labels)\n",
    "        if hist_eq:\n",
    "            img = super()._hist_eq(img, hist_eq=hist_eq)\n",
    "        else:\n",
    "            img = super()._convert_to_8bit(img)\n",
    "        \n",
    "        if save:\n",
    "            self._save_image(img, path, fformat=fformat, mask=labels)\n",
    "        else: \n",
    "            return img\n",
    "        \n",
    "    def _save_image(self, img, path, fformat: str, mask=None):\n",
    "        \"\"\"\n",
    "        Naming convention:\n",
    "        Mass-Training_P_00001_LEFT_MLO_mammo.png\n",
    "        \n",
    "        Lesion type/train or test/patient id/left or right breast/view/mask or image/exstension\n",
    "        \"\"\"\n",
    "        \n",
    "        dir_path = self._create_save_path(path)\n",
    "        fname = re.search(\"/.+/(.+_P_[0-9]+_.+?)/\", path).group(1)\n",
    "        \n",
    "        fname_img = f\"{fname}_mammo.{fformat}\"\n",
    "        save_path = os.path.join(dir_path, fname_img)\n",
    "        cv2.imwrite(save_path, img)\n",
    "        \n",
    "        if mask is not None:\n",
    "            fname_mask = f\"{fname}_mask.png\"\n",
    "            save_path = os.path.join(dir_path, fname_mask)\n",
    "            cv2.imwrite(save_path, mask)\n",
    "        \n",
    "    def _create_save_path(self, img_path):\n",
    " \n",
    "        # Create a folder from patient id    \n",
    "        patient_folder = re.search(\"_(P_[0-9]+)_\", img_path).group(1)\n",
    "        \n",
    "        save_path = os.path.join(self.save_path, patient_folder)\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        \n",
    "        return save_path\n",
    "\n",
    "    def _remove_wlines(self, img, mask=None):\n",
    "        # Removes white line artifacts present on some images\n",
    "        # https://www.hindawi.com/journals/cin/2022/8044887/\n",
    "        \n",
    "        # Get image height and width\n",
    "        h, w = img.shape[:2]\n",
    "\n",
    "        # Define the cropping parameters\n",
    "        crop_height = int(h * 0.02)\n",
    "        crop_width = int(w * 0.005)\n",
    "        \n",
    "        cropped_img = img[crop_height:-crop_height, crop_width:-crop_width]\n",
    "        if mask is not None:\n",
    "            mask = mask[crop_height:-crop_height, crop_width:-crop_width]\n",
    "        \n",
    "        return (img, mask) if mask is not None else img\n",
    "    \n",
    "    def _combine_masks(self, path):\n",
    "\n",
    "        image_info = self.df.loc[self.df.full_img_fname==path]\n",
    "\n",
    "        labels = 0\n",
    "        for i in range(image_info.shape[0]):\n",
    "            mask = image_info.iloc[i]\n",
    "            mask_px = (dicom.open(mask.mask_fname).pixelData() / 255).astype(np.uint8)\n",
    "            # Mask are coded: 1 for benign, 2 for malignant\n",
    "            labels += mask_px * mask.pathology\n",
    "\n",
    "        return labels\n",
    "    \n",
    "    def _merge_dfs(self, mammo_imgs_csv, masks_csv, case_desc_csv):\n",
    "        \n",
    "        df_full = pd.read_csv(mammo_imgs_csv)\n",
    "        df_mask = pd.read_csv(masks_csv)\n",
    "        df_mass = pd.read_csv(case_desc_csv)\n",
    "        \n",
    "        mass_type = df_full[\"PatientID\"].str.split(\"_\", n=1)[0][0]\n",
    "        df_mass[\"PatientID\"] = mass_type + \"_\" + df_mass.patient_id + \"_\" + df_mass[\"left or right breast\"] + \"_\" + df_mass[\"image view\"] + \"_\" + df_mass[\"abnormality id\"].astype(\"str\")\n",
    "        df_mask = df_mask.loc[df_mask.SeriesDescription==\"ROI mask images\",].reset_index(drop=True)\n",
    "        \n",
    "        mass_cols_keep = [\"PatientID\", \"pathology\"]\n",
    "        mask_cols_keep = [\"PatientID\", \"fname\"]\n",
    "        full_cols_keep = [\"PatientID\", \"fname\"]\n",
    "\n",
    "        df_mass = df_mass[mass_cols_keep]\n",
    "        df_mask = df_mask[mask_cols_keep]\n",
    "        df_full = df_full[full_cols_keep]\n",
    "        \n",
    "        df_mass.rename(columns={\"PatientID\": \"PathologyID\"}, inplace=True)\n",
    "        df_mask.rename(columns={\"PatientID\": \"PathologyID\", \"fname\": \"mask_fname\"}, inplace=True)\n",
    "        df_full.rename(columns={\"PatientID\": \"ImageID\", \"fname\": \"full_img_fname\"}, inplace=True)\n",
    "\n",
    "        df_all = df_mass.merge(df_mask, on=\"PathologyID\")\n",
    "        df_all[\"ImageID\"] = df_all.PathologyID.str.replace(r\"_[0-9]$\", \"\", regex=True)\n",
    "        df_all = df_all.merge(df_full, on=\"ImageID\", how=\"left\")\n",
    "        \n",
    "        df_all[\"PatientID\"] = df_all.PathologyID.str.extract(\"(P_[0-9]+)_\", expand=False)\n",
    "        df_all[\"pathology\"] = df_all.pathology.str.replace(\"_.*\",\"\", regex=True)\n",
    "        df_all[\"pathology\"].replace({\"BENIGN\":1, \"MALIGNANT\":2}, inplace=True)\n",
    "\n",
    "        df_all.sort_values(by=\"PatientID\", ignore_index=True, inplace=True)\n",
    "        \n",
    "        return df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "833a68b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-05T12:18:53.081371Z",
     "iopub.status.busy": "2023-02-05T12:18:53.081104Z",
     "iopub.status.idle": "2023-02-05T12:18:53.096353Z",
     "shell.execute_reply": "2023-02-05T12:18:53.095452Z"
    },
    "papermill": {
     "duration": 0.021401,
     "end_time": "2023-02-05T12:18:53.098307",
     "exception": false,
     "start_time": "2023-02-05T12:18:53.076906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#|export\n",
    "class MammoPreprocessorRSNA(MammoPreprocessorBase):\n",
    "    \n",
    "    def __init__(self, img_path: str, \n",
    "                 image_size: tuple=(4096,2048), dir_name: str=\"RSNA\"):\n",
    "    \n",
    "        super().__init__(img_path, image_size, dir_name)\n",
    "        \n",
    "    def preprocess_image(self, path:str, fformat: str=\"png\", hist_eq=None, save=True):\n",
    "        \n",
    "        scan, img = self._load_dicom(path)\n",
    "        \n",
    "        img = self._fix_photometric_inter(scan, img)\n",
    "        img = self._windowing(scan, img)\n",
    "        img = super()._correct_side(img)\n",
    "        img = super()._remove_background(img)\n",
    "        img = super()._crop_roi(img)\n",
    "        img = super()._resize_to_height(img, self.image_size)\n",
    "        img = super()._padresize_to_width(img, self.image_size)\n",
    "        if hist_eq:\n",
    "            img = super()._hist_eq(img, hist_eq=hist_eq)\n",
    "        else:\n",
    "            img = super()._convert_to_8bit(img)\n",
    "        \n",
    "        if save:\n",
    "            self._save_image(img, path, fformat=fformat)\n",
    "        else:\n",
    "            return img\n",
    "        \n",
    "    def _save_image(self, img, path, fformat: str):\n",
    "        \n",
    "        dir_path = self._create_save_path(path)\n",
    "        fname = re.search(\"/([0-9]+).dcm$\", path).group(1)\n",
    "        \n",
    "        fname_img = f\"{fname}.{fformat}\"\n",
    "        save_path = os.path.join(dir_path, fname_img)\n",
    "        cv2.imwrite(save_path, img)\n",
    "    \n",
    "    # https://dicom.nema.org/medical/dicom/2018b/output/chtml/part03/sect_C.11.2.html\n",
    "    def _windowing(self, scan, img):\n",
    "        \n",
    "        function = scan.VOILUTFunction\n",
    "        \n",
    "        if type(scan.WindowWidth) == list:\n",
    "            center = int(np.mean((scan.WindowCenter)))\n",
    "            width = scan.WindowWidth[0]\n",
    "        else:\n",
    "            center = scan.WindowCenter\n",
    "            width = scan.WindowWidth\n",
    "        \n",
    "        y_range = 2**scan.BitsStored - 1\n",
    "        \n",
    "        if function == 'SIGMOID':\n",
    "            img = y_range / (1 + np.exp(-4 * (img - center) / width))\n",
    "        \n",
    "        else: # LINEAR\n",
    "            \n",
    "            center -= 0.5\n",
    "            width -= 1\n",
    "            \n",
    "            below = img <= (center - width / 2)\n",
    "            above = img > (center + width / 2)\n",
    "            between = np.logical_and(~below, ~above)\n",
    "            img[below] = 0\n",
    "            img[above] = y_range\n",
    "            img[between] = ((img[between] - center) / width + 0.5) * y_range\n",
    "        \n",
    "        return img\n",
    "    \n",
    "    # https://dicom.nema.org/medical/Dicom/2017c/output/chtml/part03/sect_C.7.6.3.html\n",
    "    def _fix_photometric_inter(self, scan, img):\n",
    "        \n",
    "        # Section C.7.6.3.1.2\n",
    "        if scan.PhotometricInterpretation == \"MONOCHROME1\":\n",
    "            img = img.max() - img\n",
    "            \n",
    "        return img\n",
    "    \n",
    "    def _create_save_path(self, img_path):\n",
    " \n",
    "        patient_folder = re.search(\"/([0-9]+)/\", img_path).group(1)\n",
    "        \n",
    "        save_path = os.path.join(self.save_path, patient_folder)\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        \n",
    "        return save_path\n",
    "    \n",
    "    def _load_dicom(self, path: str):\n",
    "        dcmfile = dicom.open(path)\n",
    "        return dcmfile, dcmfile.pixelData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec57feb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-05T12:18:53.105780Z",
     "iopub.status.busy": "2023-02-05T12:18:53.105476Z",
     "iopub.status.idle": "2023-02-05T12:18:55.112954Z",
     "shell.execute_reply": "2023-02-05T12:18:55.111498Z"
    },
    "papermill": {
     "duration": 2.014188,
     "end_time": "2023-02-05T12:18:55.115632",
     "exception": false,
     "start_time": "2023-02-05T12:18:53.101444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%notebook -e preprocess.ipynb\n",
    "\n",
    "from nbdev.export import nb_export\n",
    "nb_export('preprocess.ipynb', '.')\n",
    "!rm preprocess.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 37.028581,
   "end_time": "2023-02-05T12:18:56.542167",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-02-05T12:18:19.513586",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
